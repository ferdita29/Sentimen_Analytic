# -*- coding: utf-8 -*-
"""mobilephone_rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cv4qk149VY1EwB1HOZ9w_GhM27NSuMn5

# **SYSTEM RECOMMENDATION : MOBILE RECOMMENDATION SYSTEM**
## Nama : Ferdita Lusiana
## Email : lusianaferdita@gmail.com
## Sumber Dataset :
Dataset diperoleh dari kaggle dengan judul **Mobile Recommendation System Dataset** (https://www.kaggle.com/datasets/gyanprakashkushwaha/mobile-recommendation-system-dataset) dengan jumlah dataset 2546 data.

# **Proyek Overview**

Di era digital saat ini, konsumen memiliki begitu banyak pilihan dalam membeli smartphone, yang hadir dengan variasi spesifikasi teknis seperti kapasitas RAM, ukuran kamera, daya baterai, sistem operasi, dan kisaran harga yang sangat luas. Banyaknya pilihan ini seringkali membuat pengguna kesulitan dalam menentukan produk yang paling sesuai dengan kebutuhan dan preferensinya.

Proyek ini bertujuan untuk membangun sistem rekomendasi smartphone berbasis data yang dapat membantu pengguna dalam memilih smartphone terbaik berdasarkan spesifikasi dan ulasan pengguna. Dataset yang digunakan memuat informasi penting seperti nama produk, rating pengguna, harga, tautan gambar produk, serta deskripsi teknis (corpus) yang mencakup RAM, penyimpanan internal, baterai, kamera, dan sistem operasi.

# ðŸ’¼ **Business Understanding**

## ðŸ” **Problem Statements**
1. Bagaimana persebaran penggunaan smartphone berdasarkan nama smartphone dan rentang harga yang paling diminati pengguna?
2. Bagaimana performa nama dan model smartphone berdasarkan fitur teknis seperti storage/ram, OS/prosesor, kamera, display, jaringan, dan baterai dibandingkan dengan rating pengguna?
3. bagaimana spesifikasi teknis smartphone (corpus) mempengaruhi dalam menentukan rating smartphone di berbagai segmen harga?
4. Bagaimana cara membuat sistem rekomendasi smartphone yang optimal dan dapat diimplementasikan secara efektif?

## ðŸŽ¯ **Goals**
1. Mengetahui persebaran dan popularitas smartphone berdasarkan merek dan segmen harga yang paling diminati pengguna.
2. Menganalisis performa smartphone dengan memvisualisasikan hubungan antara fitur teknis dan rating pengguna.
3. Mengevaluasi pengaruh spesifikasi teknis smartphone terhadap rating di berbagai kategori harga menggunakan visualisasi seperti heatmap dan scatterplot.
4. Mengembangkan sistem rekomendasi smartphone menggunakan algoritma content-based filtering dan collaborative filtering, serta mengevaluasi performanya dengan metrik akurasi yang sesuai.

## ðŸ› ï¸ **Solution Approach**
Untuk mencapai tujuan di atas, pendekatan berikut akan digunakan dalam analisis dan pengembangan sistem rekomendasi smartphone:
 1. Mengimplementasikan Exploratory Data Analysis (EDA) untuk analisis dan visualisasi data.
 2. Mengimplementasikan content-based filtering approach menggunakan algoritma cosine similarity.
 3. Mengimplementasikan collaborative-based filtering approach menggunakan algoritma deep learning.

# **Data Understanding**

## **Import Library**

Import Semua Library yang diperlukan
"""

import os
import shutil
import zipfile
import re
from IPython.display import display
import textwrap
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, classification_report

#membuka zip menjadi folder
with zipfile.ZipFile("/content/archive.zip", "r") as zip_ref:
    zip_ref.extractall("dataset")


#membaca csv dalam folder
data= pd.read_csv("/content/dataset/mobile_recommendation_system_dataset.csv")

# Display the first few rows
data.head()

"""### Deskripsi Variabel

Berikut adalag arti dari variabel-variabel dataset diatas

| **Nama Variabel** | **Tipe Data**    | **Deskripsi**                                                                                                                                                             |
| ----------------- | ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `name`            | `String`         | Nama lengkap smartphone, termasuk merk, model, varian warna, dan kapasitas memori.                                                                                        |
| `ratings`         | `Float`          | Nilai rata-rata ulasan pengguna (range 1â€“5), menunjukkan tingkat kepuasan terhadap produk.                                                                                |
| `price`           | `Integer/String` | Harga smartphone. Perlu dibersihkan dari simbol mata uang seperti `â‚¹` untuk dianalisis secara numerik.                                                                    |
| `imgURL`          | `String (URL)`   | URL gambar produk dari e-commerce. Umumnya digunakan untuk visualisasi atau aplikasi berbasis antarmuka.                                                                  |
| `corpus`          | `String`         | Deskripsi gabungan dari spesifikasi teknis: RAM, ROM, sistem operasi, prosesor, dan fitur lainnya. Digunakan sebagai fitur untuk pemrosesan teks atau sistem rekomendasi. |
"""

data.info()

# Menampilkan jumlah baris dan kolom pada data
total_row, total_column = data.shape
print(f"Total of rows: {total_row}")
print(f"Total of column: {total_column}")

"""Dapat dilihat bahwa data yang digunakan adalah sebanyak 2546 data dengan 5 fitur dengan terdapat 1 variabel bertipe `float64`, 4 variabel bertipe `object`.

### Statistik Deskripsi dari Data
"""

data.describe()

"""Tabel di atas memberikan informasi statistik pada masing-masing kolom, antara lain:
- Count adalah jumlah sampel pada data.
- Mean adalah nilai rata-rata.
- Std adalah standar deviasi (mengukur seberapa tersebar data).
- Min yaitu nilai minimum setiap kolom.
- 25% adalah kuartil pertama, yaitu nilai di bawah 25% data berada.
- 50% adalah kuartil kedua, juga disebut median (nilai tengah data).
- 75% adalah kuartil ketiga, yaitu nilai di bawah 75% data berada.
- Max adalah nilai maksimum

Penjelasan:

Dari tabel Data ratings menunjukkan distribusi yang cukup sempit dan condong ke arah nilai tinggi, yang mengindikasikan bahwa mayoritas pengguna memberikan penilaian positif terhadap item yang ada. Hal ini bisa menunjukkan kualitas produk/jasa yang baik atau bisa juga bias penilaian (rating bias).
"""

# Menghapus simbol rupee dan koma, lalu mengonversi menjadi float
data['price'] = data['price'].replace('[â‚¹,]', '', regex=True).astype(float)

# Cek hasil setelah dibersihkan
data['price'].head()

"""Dari hasil diatas menunjukan bahwa kolom price dengan simbol rupe dan koma dihapus dan mengonversi menjadi float."""

data.info()

def extract_storage_ram(text):
    if isinstance(text, str):
        match = re.search(r'(\d+\s?GB\s?(RAM|Storage|ROM|internal|memory).*)', text, re.IGNORECASE)
        return match.group(1) if match else None

def extract_os_processor(text):
    if isinstance(text, str):
        match = re.search(r'(Android|iOS|Snapdragon|MediaTek|Exynos|Processor.*?)(,|\.|\n|$)', text, re.IGNORECASE)
        return match.group(1) if match else None

def extract_camera(text):
    if isinstance(text, str):
        match = re.search(r'(\d{1,3}\s?MP(?:\s?(?:rear|front|triple|dual)?\s?camera)?)', text, re.IGNORECASE)
        return match.group(1) if match else None

def extract_display(text):
    if isinstance(text, str):
        match = re.search(r'(\d+\.?\d*[-\s]?(inch|inches|\"|\sdisplay).*)', text, re.IGNORECASE)
        return match.group(1) if match else None

def extract_network(text):
    if isinstance(text, str):
        match = re.search(r'\b(5G|4G|3G|Dual SIM)\b', text, re.IGNORECASE)
        return match.group(1) if match else None

def extract_battery(text):
    if isinstance(text, str):
        match = re.search(r'Capacity\s*(\d{3,5})', text, re.IGNORECASE)
        return f"{match.group(1)} mAh" if match else None

# Terapkan ke DataFrame
data['storage_ram'] = data['corpus'].apply(extract_storage_ram)
data['os_processor'] = data['corpus'].apply(extract_os_processor)
data['camera'] = data['corpus'].apply(extract_camera)
data['display'] = data['corpus'].apply(extract_display)
data['network'] = data['corpus'].apply(extract_network)
data['battery'] = data['corpus'].apply(extract_battery)

# Tampilkan hasil dalam bentuk tabel (bukan print biasa)
display(data[['name', 'storage_ram', 'os_processor', 'camera', 'display', 'network', 'battery']].head(5))

"""agar lebih mudah mengerti dataset maka corpus dipisah agar dapat mengecek apakah terjadi missing value, duplikasi, dan memudahkan visualisasi"""

# Menampilkan data duplikat
data[data.duplicated]

# Cek jumlah data sebelum menghapus duplikat
print("Jumlah data sebelum menghapus duplikat:", data.shape[0])

# Cek apakah ada data duplikat
duplicates = data[data.duplicated()]
print(f"Jumlah baris duplikat: {duplicates.shape[0]}")

"""Dari Hasil diatas terlihat bahwa ada 1 data yang mengalami duplikasi yaitu di baris ke 1696 dengan name OPPO Reno 10 5G."""

# Hapus duplikat
data= data.drop_duplicates()

# Cek jumlah data setelah menghapus duplikat
print("Jumlah data setelah menghapus duplikat:", data.shape[0])

"""Dari hasil diatas terlihat bahwa sudah dilakukan perbaikan dalam menangani data yang terduplikat."""

# Mengecek missing velue
pd.DataFrame({'Nilai yang Kosong':data.isnull().sum()})

"""Dari hasil diatas diketahui bahwa terdapat missing velue di 7 kolom yaitu corpus, storage_ram, os_processor, camera, display, network, dan battery."""

data = data.dropna()

"""code diatas untuk menghapus semua baris dalam DataFrame data yang mengandung nilai kosong (NaN)."""

# Menangani missing velue
pd.DataFrame({'Nilai yang Kosong':data.isnull().sum()})

"""Dari Hasil diatas terlihat bahwa sudah tidak ada missing velue karena sudah ditangani."""

data.shape

"""code diatas menunjukan bahwa dataset yang sudah di lakukan proses cleaning data ada 1970 data dan 11 kolom.

# **Exploratory Data Analysis (EDA)**

### Persebaran penggunaan smartphone berdasarkan nama smartphone dan rentang harga
"""

# Hitung kombinasi brand dan rentang harga terbanyak
top_combinations = (
    data.groupby(['name', 'price'])
    .size()
    .reset_index(name='count')
    .sort_values(by='count', ascending=False)
    .head(10)
)

# Filter data hanya berdasarkan kombinasi top 10 tersebut
filtered_data = data.merge(top_combinations[['name', 'price']], on=['name', 'price'])

# Visualisasi
plt.figure(figsize=(12, 6))
sns.countplot(data=filtered_data, x='price', hue='name', palette='Set2')
plt.title('Top 10 Kombinasi Brand dan Rentang Harga Smartphone Terpopuler')
plt.xlabel('Rentang Harga')
plt.ylabel('Jumlah Smartphone')
plt.legend(title='Brand', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""Kesimpulan:
- Brand dan harga adalah dua faktor utama dalam keputusan pembelian smartphone.
- Samsung dan OPPO tampil sebagai brand paling banyak dipilih di berbagai rentang harga.
- Rentang harga menengah (sekitar 10Kâ€“30K) adalah segmen pasar paling kompetitif dan diminati.
- Untuk sistem rekomendasi atau strategi pemasaran, fokuskan pada model populer di rentang harga tersebut, dengan storage 64â€“128 GB, dari brand-brand teratas seperti Samsung, OPPO, dan OnePlus.
"""

# Salin dulu data asli
df = data.copy()

# Ekstrak kapasitas penyimpanan dan RAM (dalam GB)
df['storage_gb'] = df['storage_ram'].str.extract(r'(\d+)\s*GB', expand=False).astype(float)
df['ram_gb'] = df['storage_ram'].str.extract(r'GBRAM(\d+)', expand=False).astype(float)

# Ekstrak kamera (dalam MP)
df['camera_mp'] = df['camera'].str.extract(r'(\d+)\s*MP', expand=False).astype(float)

# Ekstrak ukuran layar dari kolom display (dalam inci)
df['display_inch'] = df['display'].str.extract(r'Size.*?(\d+\.?\d*)\s*inch', expand=False).astype(float)

# Ekstrak baterai (dalam mAh)
df['battery_mah'] = df['battery'].str.extract(r'(\d+)', expand=False).astype(float)

# Konversi kolom network ke bentuk numerik sederhana (misal: 3G â†’ 3, 4G â†’ 4, 5G â†’ 5)
df['network_gen'] = df['network'].str.extract(r'(\d)G', expand=False).astype(float)

# Tampilkan hasil ekstraksi
display(df[['name', 'storage_gb', 'ram_gb', 'camera_mp', 'display_inch', 'battery_mah', 'network_gen', 'ratings']].head())

"""Dari code diatas bertujuan untuk mengekstrak fitur dari string ke float agar mudah dalam mengimplementasikan visualisasi fitur.

### Hubungan antara Rating vs RAM dan Storage
"""

plt.figure(figsize=(6,4))
sns.scatterplot(data=df, x='ram_gb', y='ratings', hue='storage_gb', size='battery_mah', palette='coolwarm', sizes=(40, 160))
plt.title('Rating vs RAM dan Storage')
plt.xlabel('RAM (GB)')
plt.ylabel('Rating Pengguna')
plt.tight_layout()
plt.show()

"""Penjelasan:
1. RAM 4â€“8 GB paling umum dan cenderung mendapat rating â‰¥ 4.0, mencerminkan performa ideal.
2. Storage â‰¥ 128 GB sering muncul pada smartphone dengan rating tinggi.
3. Ukuran baterai (dalam plot) tidak terlalu memengaruhi rating secara langsung.
4. RAM sangat besar (â‰¥ 12 GB) tidak selalu berarti rating tinggi, kemungkinan karena faktor lain seperti software atau harga.

### Scatterplot Kamera VS Rating
"""

# Ekstrak MP kamera dan mAh baterai
data['camera_mp'] = data['camera'].str.extract(r'(\d+\.?\d*)').astype(float)

plt.figure(figsize=(6, 4))
sns.scatterplot(data=data, x='camera_mp', y='ratings', palette='viridis', sizes=(40, 200))
plt.title('Kamera vs Rating')
plt.xlabel('Kamera (MP)')
plt.ylabel('Rating Pengguna')
plt.tight_layout()
plt.show()

"""Penjelasan:
1. Mayoritas kamera utama berada di kisaran 12â€“64 MP, sesuai tren pasar menengah ke atas.
2. Kamera â‰¥ 48 MP cenderung berkorelasi dengan rating â‰¥ 4.0, menandakan bahwa resolusi kamera tinggi diapresiasi oleh pengguna.
3. Namun, tidak ada korelasi linear â€” beberapa smartphone dengan kamera tinggi tetap mendapat rating sedang.

Hal ini menunjukkan bahwa megapiksel bukan satu-satunya faktor, kualitas software kamera dan fitur lain seperti OIS, AI, atau mode malam juga berperan penting dalam pengalaman pengguna.

### Boxplot Rating Berdasarkan Generasi Jaringan
"""

plt.figure(figsize=(6,4))
sns.boxplot(data=df, x='network_gen', y='ratings', palette='Set3')
plt.title('Rating Berdasarkan Generasi Jaringan')
plt.xlabel('Jaringan')
plt.ylabel('Rating Pengguna')
plt.show()

"""Penjelasan:
1. Smartphone 5G cenderung memiliki rating lebih tinggi secara konsisten dibanding 3G dan 4G.
2. Median rating untuk 5G terlihat lebih tinggi, dengan distribusi yang lebih stabil dan jarang outlier.
3. Sebaliknya, 3G dan 4G menunjukkan variasi rating yang lebih besar, dengan beberapa perangkat 4G mendapat rating rendah.

Hal ini menunjukkan bahwa dukungan jaringan terbaru (5G) menjadi nilai tambah dalam penilaian pengguna â€” meskipun bisa jadi karena ponsel 5G juga dibekali spesifikasi lebih tinggi.

### Kolerasi Fitur Teknis dengan Rating Pengguna
"""

plt.figure(figsize=(7,5))
sns.heatmap(df[['storage_gb', 'ram_gb', 'camera_mp', 'display_inch', 'battery_mah', 'network_gen', 'ratings']].corr(), annot=True, cmap='YlGnBu')
plt.title("Korelasi Fitur Teknis dengan Rating Pengguna")
plt.show()

"""Penjelasan:
1. Rating pengguna memiliki korelasi lemah dengan hampir semua fitur teknis (nilai korelasi mendekati 0).
2. RAM, storage, kamera, dan baterai hanya menunjukkan korelasi sangat rendah terhadap rating (di bawah 0.2), artinya peningkatan spesifikasi teknis tidak selalu berbanding lurus dengan kepuasan pengguna.
3. Network generation (3G/4G/5G) juga tidak menunjukkan hubungan kuat terhadap rating, meskipun ada tren 5G cenderung disukai.

Korelasi paling tinggi pun tetap berada dalam kategori lemah, sehingga faktor lain seperti harga, brand, desain, dan pengalaman pengguna kemungkinan besar lebih menentukan dalam penilaian.

### Heatmap Korelasi Fitur Teknis vs Rating per Segmen Harga
"""

for segment in ['Low', 'Mid', 'High']:
    subset = df[df['price'] == segment]
    plt.figure(figsize=(6, 4))
    sns.heatmap(subset[['storage_gb', 'ram_gb', 'camera_mp', 'display_inch',
                        'battery_mah', 'network_gen', 'ratings']].corr(),
                annot=True, cmap='YlGnBu')
    plt.title(f"Korelasi Fitur Teknis vs Rating - Harga {segment}")
    plt.tight_layout()
    plt.show()

"""Kesimpulan:
1. Segmen Harga Low
 - Korelasi lemah secara umum antara fitur teknis dan rating.
 - Fitur seperti RAM, storage, dan kamera memiliki korelasi positif kecil hingga sedang terhadap rating.
 - Display dan baterai menunjukkan pengaruh minim, mengindikasikan bahwa di segmen ini pengguna cenderung puas dengan fitur dasar asalkan harganya terjangkau.
2. Segmen Harga Mid
 - RAM dan kamera mulai menunjukkan korelasi positif yang lebih kuat terhadap rating.
 - Storage dan baterai juga mulai memberi kontribusi terhadap kepuasan pengguna.
 - Ini menunjukkan bahwa di segmen menengah, pengguna mulai mempertimbangkan kombinasi performa dan daya tahan.
3. Segmen Harga High
Korelasi terkuat ditemukan di segmen ini, terutama pada:
 - RAM dan rating: menandakan performa multitasking sangat penting.
 - Storage dan kamera: fitur premium ini memengaruhi persepsi kualitas pengguna.

Fitur-fitur teknis secara umum memiliki korelasi yang lebih jelas terhadap rating, mencerminkan ekspektasi pengguna yang tinggi di segmen ini.

# **Modelling**

## **Content Based Filtering**

### A. Data Preparation

Untuk content-based filtering, kita akan fokus pada name,price,ratings dan corpus yang sudah disatukan untuk menjadi dasar pembuatan sistem rekomendasi tersebut. Oleh karena itu, dataframe hanya terdiri 4 kolom dari data yang dimiliki.
"""

# membuat data dengan mendrop kolom yang tidak diperlukan dan akan digabung
dataset_content = data.drop(columns=[ 'imgURL'])

# Membuat dataset_content dengan hanya menyimpan kolom yang diperlukan
dataset_content = data[["name", "price", "ratings", "corpus"]].copy()

# Membuat kolom gabungan untuk keperluan rekomendasi/representasi (misalnya untuk TF-IDF)
dataset_content["brand_product"] = data["name"].astype(str) + " | $" + data["price"].astype(str) + " | Rating: " + data["ratings"].astype(str)

# Menampilkan 5 data teratas
dataset_content.head()

"""ðŸ” Kesimpulan
1. Tujuan utama preprocessing adalah menyederhanakan dan menyiapkan data agar dapat digunakan dalam sistem rekomendasi berbasis konten.
2. Dataset telah difilter menjadi dataset_content yang hanya berisi kolom penting:
name, price, ratings, dan corpus.
3. Dibuat kolom gabungan baru brand_product yang menggabungkan:
 - Nama produk,
 - Harga,
 - Rating,
menjadi satu string representatif seperti:
"REDMI Note 12 Pro 5G (Onyx Black, 128 GB) | $23999.0 | Rating: 4.2".
 - dan Corpus.
4. Kolom brand_product ini akan digunakan sebagai identitas utama untuk pencocokan dan pemanggilan rekomendasi produk serupa.

Hasil akhir dari preprocessing ini memungkinkan sistem rekomendasi menampilkan produk-produk HP yang mirip, baik berdasarkan nama, harga, maupun rating-nya, secara relevan dan mudah dibaca.


"""

# Mengonversi data series "name" menjadi list
product_name = dataset_content["name"].tolist()

# Mengonversi data series "price" menjadi list
price_list = dataset_content["price"].tolist()

# Mengonversi data series "ratings" menjadi list
ratings_list = dataset_content["ratings"].tolist()

# Mengonversi data series "corpus" menjadi list (ini biasanya dipakai untuk TF-IDF)
corpus_list = dataset_content["corpus"].tolist()

# Mengonversi data series "ratings" menjadi list
brand_product = dataset_content["brand_product"].tolist()

# Menampilkan jumlah data dari masing-masing list
print(f"Terdapat {len(product_name)} data product name")
print(f"Terdapat {len(price_list)} data harga")
print(f"Terdapat {len(ratings_list)} data ratings")
print(f"Terdapat {len(brand_product)} data brand_product")
print(f"Terdapat {len(corpus_list)} data corpus")

# Membuat dataframe untuk content-based filtering
content_based_data = pd.DataFrame({
    "name": data["name"],
    "price": data["price"],
    "ratings": data["ratings"],
    "corpus": data["corpus"],
})

# Tambahkan kolom brand_product untuk tampilan gabungan
content_based_data["brand_product"] = (
    data["name"].astype(str) + " | $" + data["price"].astype(str) + " | Rating: " + data["ratings"].astype(str)
)

# Menampilkan 5 baris pertama
content_based_data.head()

"""Kesimpulan:

Dataframe content_based_data dibuat untuk mendukung sistem rekomendasi berbasis konten dengan menggabungkan informasi penting produk seperti nama, harga, rating, dan teks deskripsi (corpus). Kolom tambahan brand_product dibuat sebagai representasi gabungan yang memudahkan tampilan informasi produk secara ringkas dan informatif.
"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data corpus
tf.fit(content_based_data["brand_product"])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(content_based_data["brand_product"])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""Kesimpulan:

Kode ini mengubah matriks TF-IDF yang awalnya dalam format sparse matrix menjadi matriks padat (dense matrix) menggunakan fungsi todense(). Ini memudahkan visualisasi dan manipulasi data dalam bentuk array lengkap, meskipun bisa memakan lebih banyak memori terutama untuk dataset besar.
"""

# Membentuk tabel dari nama corpus beserta kolom yang berisi  category,ingredient,skin type berdasarkan tfidf
pd.DataFrame(
    tfidf_matrix.todense(),
    columns = tf.get_feature_names_out(),
    index = content_based_data.brand_product
)

"""Kesimpulan:

Kode ini membentuk DataFrame dari matriks TF-IDF dengan baris-baris yang mewakili setiap produk (berdasarkan brand_product) dan kolom-kolom yang merepresentasikan kata-kata unik (fitur) dalam teks. DataFrame ini menunjukkan bobot TF-IDF untuk setiap kata pada masing-masing produk, yang dapat digunakan untuk menganalisis kemiripan berdasarkan kategori, bahan (ingredient), dan jenis kulit (skin type). Ini menjadi dasar penting dalam penerapan content-based filtering.

## B. Model and Result
"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Kesimpulan:

Kode ini menghitung cosine similarity dari matriks TF-IDF untuk mengukur sejauh mana tiap produk mirip satu sama lain berdasarkan fitur teksnya. Hasilnya berupa matriks nilai antara 0 hingga 1, di mana nilai 1 menunjukkan bahwa dua produk memiliki deskripsi teks yang identik. Matriks ini digunakan sebagai dasar dalam sistem rekomendasi berbasis konten untuk menemukan produk-produk yang paling mirip.
"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa brand dan product
dataset_content["brand_product"] = data["name"].astype(str) + " | $" + data["price"].astype(str) + " | Rating: " + data["ratings"].astype(str)
cosine_sim_df = pd.DataFrame(cosine_sim, index = dataset_content["brand_product"], columns = dataset_content['brand_product'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap produk
cosine_sim_df.sample(5, axis = 1).sample(15, axis = 0)

"""Kesimpulan:

Kode ini membentuk DataFrame cosine_sim_df dari matriks cosine similarity, dengan baris dan kolom diberi label brand_product (gabungan nama, harga, dan rating produk). Struktur ini memudahkan analisis kemiripan antar produk secara langsung berdasarkan representasi teks. Hasil sampling dari matriks menunjukkan beberapa nilai kemiripan antar produk, yang bisa digunakan untuk menampilkan rekomendasi produk serupa dalam sistem content-based filtering.

## C. Testing System Recommendation
"""

def content_based_phone_recommendations(phone_name, similarity_data=cosine_sim_df,
                                        items=content_based_data, k=10):
    # Mengambil indeks produk yang paling mirip berdasarkan cosine similarity
    index = similarity_data.loc[:, phone_name].to_numpy().argpartition(range(-1, -k, -1))

    # Mengambil nama-nama produk terdekat berdasarkan similarity tertinggi
    closest = similarity_data.columns[index[-1: -(k + 2): -1].flatten()]

    # Menghapus produk itu sendiri dari hasil rekomendasi
    closest = closest.drop(phone_name, errors="ignore")

    # Mengembalikan DataFrame hasil rekomendasi
    return pd.DataFrame(closest).merge(items, left_on=0, right_on="name").drop(columns=0).head(k)

"""Penjelasan:

Code ini bertujuan untuk menguji sistem rekomendasi berbasis konten (content-based recommendation system) untuk produk handphone.
"""

# Menampilkan baris sesuai dengan nama brand_product
content_based_data[content_based_data.brand_product.eq('SAMSUNG Galaxy M04 (Light Green, 64 GB) | $8185.0 | Rating: 4.1')]

"""Dari hasil diatas menunjukan bahwa code berhasilkan menampilkan baris sesuai dengan nama brand_product yang diuji coba."""

content_based_phone_recommendations('SAMSUNG Galaxy')

"""Kesimpulan:
1. Brand Awareness Tinggi
Produk dengan nama "SAMSUNG" cukup banyak muncul, menunjukkan bahwa merek ini memiliki varian produk yang luas dan dominan di pasaran.
2. Ragam Harga
Produk Samsung tersebar di berbagai tingkatan harga, dari entry-level hingga high-end. Ini menunjukkan strategi segmentasi pasar yang kuat.
3. Rating Konsisten
Banyak produk Samsung yang memiliki rating pengguna â‰¥ 4.0, menunjukkan konsistensi kualitas dan kepuasan pelanggan.
4. Kombinasi Spesifikasi dan Merek
Meski beberapa spesifikasi bisa setara dengan brand lain, nama besar Samsung tampaknya tetap memengaruhi persepsi pengguna dan memberi keunggulan dalam rating dan kepercayaan.

Hasil pencarian ini dapat digunakan sebagai basis awal untuk memberikan rekomendasi produk serupa, terutama dalam sistem content-based recommendation.

# **Collaborative Based Filtering**

## **A. Data Preparation**
"""

# membuat data dengan mendrop kolom yang tidak diperlukan dan akan digabung
dataset_content = data.drop(columns=[ 'imgURL'])

# Membuat dataset_content dengan hanya menyimpan kolom yang diperlukan
dataset_filtering = data[["name", "price", "ratings", "corpus"]].copy()

# Membuat kolom gabungan untuk keperluan rekomendasi/representasi (misalnya untuk TF-IDF)
# Misalnya kamu ingin menyatukan informasi untuk keperluan tampilan atau pencarian
dataset_filtering["brand_product"] = data["name"].astype(str) + " | $" + data["price"].astype(str) + " | Rating: " + data["ratings"].astype(str)

# Menampilkan 5 data teratas
dataset_filtering.head()

"""ðŸ” Kesimpulan
1. Tujuan utama preprocessing adalah menyederhanakan dan menyiapkan data agar dapat digunakan dalam sistem rekomendasi berbasis konten.
2. Dataset telah difilter menjadi dataset_content yang hanya berisi kolom penting:
name, price, ratings, dan corpus.
3. Dibuat kolom gabungan baru brand_product yang menggabungkan:
 - Nama produk,
 - Harga,
 - Rating,
menjadi satu string representatif seperti:
"REDMI Note 12 Pro 5G (Onyx Black, 128 GB) | $23999.0 | Rating: 4.2".
 - dan Corpus.
4. Kolom brand_product ini akan digunakan sebagai identitas utama untuk pencocokan dan pemanggilan rekomendasi produk serupa.

Hasil akhir dari preprocessing ini memungkinkan sistem rekomendasi menampilkan produk-produk HP yang mirip, baik berdasarkan nama, harga, maupun rating-nya, secara relevan dan mudah dibaca.


"""

# Create the "product_id" column
dataset_filtering['product_id'] = dataset_filtering['brand_product'].apply(lambda x: x.split()[0][:3].upper()) + data.index.astype(str)
dataset_filtering.head()

"""penjelasan:

Kolom product_id dibuat untuk tiap produk dengan mengambil tiga huruf depan produk dan index dari produk tersebut.
"""

# Mengubah product_id menjadi list tanpa nilai yang sama
track_ids = dataset_filtering["product_id"].unique().tolist()
print("list track_id: ", track_ids)

# Melakukan encoding terhadap track_id
track_to_track_encoded = {x: i for i, x in enumerate(track_ids)}
print("encoded track_id : ", track_to_track_encoded)

# Melakukan proses encoding angka ke track_id
track_encoded_to_track = {i: x for i, x in enumerate(track_ids)}
print("encoded angka ke track_id: ", track_encoded_to_track)

"""Kesimpulan:
1. Proses encoding product_id menjadi angka numerik berhasil dilakukan secara sistematis dan efisien.
2. Ini merupakan tahapan penting dalam sistem rekomendasi, karena banyak algoritma (seperti cosine similarity atau matrix factorization) membutuhkan data dalam bentuk numerik.
3. Adanya dua arah mapping (id â†’ angka dan angka â†’ id) memudahkan konversi saat interpretasi hasil rekomendasi nanti.

Langkah ini menunjukkan bahwa data sudah siap digunakan untuk pelatihan model rekomendasi atau perhitungan similarity.
"""

# Mengubah product_brand menjadi list tanpa nilai yang sama
track_name = dataset_filtering["brand_product"].unique().tolist()
print(track_name)

# Melakukan encoding terhadap product_brand
name_to_name_encoded = {x: i for i, x in enumerate(track_name)}
print("encoded track_id : ", name_to_name_encoded)

# Melakukan proses encoding angka ke product_brand
name_encoded_to_name = {i: x for i, x in enumerate(track_name)}
print("encoded track_id : ", name_encoded_to_name)

"""ðŸ§  Kesimpulan:
1. Tujuan utama proses ini adalah mempersiapkan data agar efisien dan siap diproses oleh model dengan mengubah nama produk (teks) menjadi angka.
2. Strategi mapping dua arah (nama â†’ angka dan angka â†’ nama) adalah praktik standar yang sangat baik untuk menjaga akurasi serta kemudahan interpretasi dalam sistem rekomendasi dan machine learning.


"""

# Mapping track_id ke dataframe track
dataset_filtering["track"] = dataset_filtering["product_id"].map(track_to_track_encoded)

# Mapping track_name ke dataframe name
dataset_filtering["name"] = dataset_filtering["brand_product"].map(name_to_name_encoded)

"""Kesimpulan:

Proses mapping product_id dan brand_product ke bentuk numerik (track dan name) membuat data lebih efisien untuk diproses oleh sistem rekomendasi. Ini membantu komputasi lebih cepat, konsisten, dan siap digunakan dalam analisis atau model machine learning.

"""

# Mendapatkan jumlah track_id
num_track = len(track_to_track_encoded)
print(num_track)

# Mendapatkan jumlah track_name
num_name = len(name_encoded_to_name)
print(num_name)

# Mencari nilai minimum popularity
min_popularity = min(dataset_filtering["ratings"])

# Mencari nilai maksimal popularity
max_popularity = max(dataset_filtering["ratings"])

print("Number of Track ID: {}, Number of Track Name: {}, Min popularity: {}, Max popularity: {}".format(
    num_track, num_name, min_popularity, max_popularity
))

"""Penjelasan:

1. Dataset memiliki 1970 Track ID dan 1943 Track Name.
2. Ini menunjukkan kemungkinan ada beberapa track yang memiliki lebih dari satu ID atau redundansi dalam pengkodean ID.
3. Nilai rating atau popularitas berada pada rentang 2.9 (minimum) hingga 4.8 (maksimum).
4. Rentang nilai ini bisa menandakan bahwa data rating cenderung positif, karena nilai minimum tidak terlalu rendah.
"""

# Mengacak dataset
collaborative_based = dataset_filtering[["track", "name", "ratings"]].sample(frac = 1, random_state = 42)
collaborative_based

"""Penjelasan:

1. Data telah diacak secara menyeluruh (100%) menggunakan fungsi .sample(frac=1).
2. Hal ini bertujuan untuk menghilangkan bias urutan data, yang penting sebelum digunakan dalam model collaborative filtering.
3. Parameter random_state=42 memastikan bahwa proses pengacakan dapat direproduksi, penting untuk debugging dan eksperimen ilmiah.


"""

# Membuat variabel x untuk mencocokkan data track dan nama menjadi satu value
x = collaborative_based[["track", "name"]].values

# Membuat variabel y untuk membuat popularity dari hasil
y = collaborative_based["ratings"].apply(lambda x: (x - min_popularity) / (max_popularity - min_popularity)).values

# Membagi data menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * data.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Penjelasan:

1. Proses ini merupakan langkah penting dalam pipeline machine learning: pemisahan data, normalisasi target, dan pembentukan fitur input.
2. Dengan input x sebagai pasangan [track_id, name_id] dan output y sebagai popularitas yang dinormalisasi, model bisa dilatih untuk memprediksi popularitas suatu track berdasarkan kombinasi track dan nama.
3. Teknik ini sangat cocok untuk sistem rekomendasi berbasis prediksi skor/rating, seperti yang biasa digunakan dalam collaborative filtering berbasis regresi atau matrix factorization.

## **B. Modelling**
"""

class RecommenderNet(tf.keras.Model):
    def __init__(self, num_track, num_name, embedding_size, **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.num_track = num_track
        self.num_name = num_name
        self.embedding_size = embedding_size

        # Embedding layer untuk track (item)
        self.track_embedding = layers.Embedding(
            input_dim=num_track,
            output_dim=embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )

        # Embedding layer untuk name (user)
        self.name_embedding = layers.Embedding(
            input_dim=num_name,
            output_dim=embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )

        # Embedding layer untuk bias
        self.name_bias = layers.Embedding(input_dim=num_name, output_dim=1)
        self.track_bias = layers.Embedding(input_dim=num_track, output_dim=1)

    def call(self, inputs):
        """
        inputs: tensor shape (batch_size, 2), di mana
          - inputs[:, 0] = index track (item)
          - inputs[:, 1] = index name (user)
        """
        # Ambil vektor embedding dan bias untuk track/item
        track_vector = self.track_embedding(inputs[:, 0])    # shape (batch_size, embedding_size)
        track_bias = self.track_bias(inputs[:, 0])           # shape (batch_size, 1)

        # Ambil vektor embedding dan bias untuk name/user
        name_vector = self.name_embedding(inputs[:, 1])      # shape (batch_size, embedding_size)
        name_bias = self.name_bias(inputs[:, 1])             # shape (batch_size, 1)

        # Hitung dot product antara vektor track dan name:
        # hasil shape => (batch_size, )
        dot_product = tf.reduce_sum(track_vector * name_vector, axis=1, keepdims=True)

        # Tambahkan bias dan aktifkan sigmoid
        x = dot_product + track_bias + name_bias
        return tf.nn.sigmoid(x)

# Inisialisasi model
model = RecommenderNet(num_track, num_name, 50)

# Model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate = 0.001),
    metrics = [tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 32,
    epochs = 35,
    validation_data = (x_val, y_val)
)

"""## Testing System Recommendation"""

# Membuat line plot untuk menunjukkan metrik evaluasi
plt.plot(history.history["root_mean_squared_error"])
plt.plot(history.history["val_root_mean_squared_error"])

# Menambahkan judul, label, dan legend pada plot
plt.title("Metrik Evaluasi pada Model")
plt.ylabel("Root Mean Squared Error (RMSE)")
plt.xlabel("Epoch")
plt.legend(["Training", "Validation"], loc = "upper right")

# Menampilkan plot
plt.show()

def recommend_tracks_based_on_track_name(track_name, top_n = 10):
    # Memeriksa apakah nama track ada di dalam mapping nama
    if track_name not in name_to_name_encoded:
        print(f"Track dengan judul '{track_name}' tidak ditemukan.")
        return

    # Encoding nama track sesuai dengan nilai encodingnya
    track_name_encoded = name_to_name_encoded[track_name]

    # Membuat list seluruh ID track yang ada
    all_track_ids = list(track_to_track_encoded.values())

    # Mempersiapkan ID dan nama track untuk prediksi
    track_name_array = np.array([[track_name_encoded]] * len(all_track_ids))
    track_id_array = np.array(all_track_ids).reshape(-1, 1)

    # Membentuk array ID dan nama track untuk prediksi
    track_name_track_id_array = np.hstack((track_id_array, track_name_array))

    # Memprediksi rating berdasarkan nama track yang dipilih
    popularity = model.predict(track_name_track_id_array).flatten()

    # Mendapatkan Top-N rekomendasi
    top_popularity_indices = popularity.argsort()[-top_n:][::-1]
    recommended_encoded_track_ids = [all_track_ids[x] for x in top_popularity_indices]

    # Mapping ID track yang sudah di encoding ke dataset awal
    recommended_track_ids = [track_encoded_to_track.get(product_id) for product_id in recommended_encoded_track_ids]

    # Menampilkan Top-N rekomendasi berdasarkan nama track
    print(f"Rekomendasi berdasarkan track dengan brand dan produk: '{track_name}'")
    print("10 Rekomendasi smartphone yang cocok untuk kamu:")
    for product_id in recommended_track_ids:
        if product_id is not None:
            # Output the actual track name
            track_info = dataset_filtering[dataset_filtering["product_id"] == product_id]
            if not track_info.empty:
                print(f" produk {track_info['brand_product'].values[0]} dengan spesifikasi {track_info['corpus'].values[0]} dan rating {track_info['ratings'].values[0]}")
            else:
                print(f"ID Track '{product_id}' tidak ada di dalam dataset.")

dataset_filtering[dataset_filtering.brand_product.eq('OPPO A78 5G (Glowing Black, 128 GB) | $18142.0 | Rating: 4.3')]

# Memanggil fungsi untuk mendapatkan top 10 rekomendasi
recommend_tracks_based_on_track_name(('OPPO A78 5G (Glowing Black, 128 GB) | $18142.0 | Rating: 4.3'), top_n=10)